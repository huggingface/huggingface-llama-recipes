{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8374a3",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of the Inference API to test the large Llama 3.1 model with 405B parameters! Access is free for [Hugging Face Pro](https://huggingface.co/pricing#pro) users.\n",
    "\n",
    "A quantized version of the model is deployed on Hugging Face, and you can query it using huggingface_hub's Inference Client. Ensure you have huggingface_hub library installed or run the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afba198",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709fe89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient, get_token, login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aedded",
   "metadata": {},
   "source": [
    "Please, ensure you are logged in to Hugging Face or run the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2084476",
   "metadata": {},
   "source": [
    "We initialize a client for the Inference API endpoint and pass our HF token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9914c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = get_token()\n",
    "client = InferenceClient(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e8c04",
   "metadata": {},
   "source": [
    "We send a list of messages to the endpoint. The appropriate chat template will be automatically applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf8af8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.1-405B-Instruct-FP8\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful an honest programming assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Is Rust better than Python?\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472f0d2",
   "metadata": {},
   "source": [
    "Since streaming mode was enabled, we'll receive incremental responses from the server rather than waiting for the full response. We can iterate through the stream like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc56aa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both Rust and Python are excellent programming languages, but they have different strengths, weaknesses, and use cases. Which one is \"better\" ultimately depends on your specific needs, goals, and preferences.\n",
      "\n",
      "Here's a brief comparison:\n",
      "\n",
      "**Rust:**\n",
      "\n",
      "Pros:\n",
      "\n",
      "1. **Memory safety**: Rust is designed to prevent common errors like null pointer dereferences and buffer overflows, making it a great choice for systems programming and building secure, reliable software.\n",
      "2. **Performance**: Rust is compiled to machine code, which means it can be as fast as C++ or C.\n",
      "3. **Concurrency**: Rust has strong support for concurrent programming, making it suitable for building high-performance, parallel systems.\n",
      "\n",
      "Cons:\n",
      "\n",
      "1. **Steeper learning curve**: Rust has a unique syntax and borrow checker, which can take time to learn.\n",
      "2. **Smaller community**: While growing, Rust's community is smaller than Python's.\n",
      "\n",
      "**Python:**\n",
      "\n",
      "Pros:\n",
      "\n",
      "1. **Ease of use**: Python has a simple syntax and is often taught as a first programming language.\n",
      "2. **Large community**: Python has a massive and active community, with many libraries and frameworks available.\n",
      "3. **Rapid development**: Python's syntax and nature make it ideal for rapid prototyping and development.\n",
      "\n",
      "Cons:\n",
      "\n",
      "1. **Slower performance**: Python is an interpreted language, which can make it slower than compiled languages like Rust.\n",
      "2. **Memory management**: Python's garbage collection can lead to performance issues if not managed properly.\n",
      "\n",
      "When to choose Rust:\n",
      "\n",
      "* Systems programming (e.g., operating systems, file systems)\n",
      "* High-performance applications (e.g., games, video editing)\n",
      "* Building secure, reliable software (e.g., cryptography, security tools)\n",
      "\n",
      "When to choose Python:\n",
      "\n",
      "* Rapid prototyping and development\n",
      "* Data analysis, science, and machine learning (e.g., NumPy, Pandas, TensorFlow)\n",
      "* Web development (e.g., Django, Flask)\n",
      "* Scripting and automation\n",
      "\n",
      "In summary, Rust is a great choice when you need performance, memory safety, and concurrency, while Python excels in ease of use, rapid development, and data analysis. Ultimately, the choice between Rust and Python depends on your specific project requirements and your personal preferences."
     ]
    }
   ],
   "source": [
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
