{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e4cd7f",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Llama 3.2 is a state-of-the-art large language model (LLM) developed by Meta (formerly Facebook). It is designed to be a successor to the earlier Llama 2 model and is based on the Llama architecture. This model can be used for a variety of tasks, including language understanding,  Retrieval-Augmented Generation (RAG), and more.\n",
    "\n",
    "LangChain is an open-source framework that simplifies the creation of LLM applications through the use of \"chains.\" Chains are LangChain-specific components that can be combined for a variety of AI use cases, including RAG.\n",
    "\n",
    "By integrating Atlas Vector Search with LangChain, you can use Atlas as a vector database and use Atlas Vector Search to implement RAG by retrieving semantically similar documents from your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f45de0d",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To complete this tutorial, you must have the following:\n",
    "\n",
    "- Llama running in GPU or Llama.cpp running locally on your GPU/CPU.\n",
    "\n",
    "- Sign up for a `free` acount at mongodb atlas. This will provide you an Atlas cluster for `free` running MongoDB version 6.0.11, 7.0.2, or later (including RCs).\n",
    "\n",
    "- An environment to run interactive Python notebooks such as Colab or local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c126c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain python-dotenv langchain-community langchain-core langchain-mongodb langchain-openai pymongo pypdf ipykernel notebook datasets transformers[torch] bitsandbytes pandas pillow sentence-transformers llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c950ed5e-06f4-4750-ae99-7b430ed2a206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/.local/share/virtualenvs/huggingface-llama-recipes-RmwcKZVd/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import getpass, os, pymongo, pprint, json\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from pymongo import MongoClient\n",
    "from pymongo.operations import SearchIndexModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61c5478",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Here we are using a simple invoice dataset `mychen76/invoices-and-receipts_ocr_v1` containing OCR extracted text, parsed data, id, and images.\n",
    "you can change this dataset to any other dataset that has a similar structure and you are interested to build a RAG pipeline on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf33c000-0784-44f9-a8c6-2452c79e33a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/.local/share/virtualenvs/huggingface-llama-recipes-RmwcKZVd/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'id', 'parsed_data', 'raw_data'],\n",
       "    num_rows: 125\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"mychen76/invoices-and-receipts_ocr_v1\", split=\"test\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b071129",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATLAS_CONNECTION_STRING = getpass.getpass(\"MongoDB Atlas SRV Connection String:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09246c97",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "- Your connection string should use the following format:\n",
    "\n",
    "`mongodb+srv://<db_username>:<db_password>@<clusterName>.<hostname>.mongodb.net`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b729363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your Atlas cluster\n",
    "client = MongoClient(ATLAS_CONNECTION_STRING)\n",
    "\n",
    "# Define collection and index name\n",
    "db_name = \"langchain_db\"\n",
    "collection_name = \"invoice_llama\"\n",
    "atlas_collection = client[db_name][collection_name]\n",
    "vector_search_index = \"invoice_llama_vector_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516a41b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/.local/share/virtualenvs/huggingface-llama-recipes-RmwcKZVd/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/var/folders/6q/mv1t578n5dd41214yd5lkclh0000gn/T/ipykernel_2753/3723805121.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
      "_id or id key found in metadata. Please pop from each dict and input as separate list.Retrieving methods will include the same id as '_id' in metadata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 125 documents.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize the sentence transformer model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Create a LangChain compatible embedding object\n",
    "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "\n",
    "# Prepare documents for vector store\n",
    "documents = []\n",
    "for item in ds:\n",
    "    parsed_data = json.loads(item['parsed_data'])\n",
    "    content = f\"Invoice ID: {item['id']}\\n\"\n",
    "    content += f\"Parsed Data: {parsed_data}\\n\"\n",
    "    \n",
    "    doc = Document(\n",
    "        page_content=content,\n",
    "        metadata={\n",
    "            \"id\": item['id']\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "# Create the vector store\n",
    "vector_store = MongoDBAtlasVectorSearch.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    collection=atlas_collection,\n",
    "    index_name=vector_search_index\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74430a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'invoice_llama_vector_index'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create your index model, then create the search index\n",
    "search_index_model = SearchIndexModel(\n",
    "    definition={\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"numDimensions\": 384,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filter\",\n",
    "                \"path\": \"id\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    name=\"invoice_llama_vector_index\",\n",
    "    type=\"vectorSearch\"\n",
    ")\n",
    "\n",
    "atlas_collection.create_search_index(model=search_index_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a8b9d0",
   "metadata": {},
   "source": [
    "### Semantic Search with Score\n",
    "searching invoice id: 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1650d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'_id': '66fbb10d096d93b82a6ef714', 'id': '38'}, page_content='Invoice ID: 38\\nParsed Data: {\\'xml\\': \\'<s_receipt><s_total>$48.40</s_total><s_tips></s_tips><s_time>7:43:29PM</s_time><s_telephone>(212)579-5959</s_telephone><s_tax>3.95</s_tax><s_subtotal>44.45</s_subtotal><s_store_name>ARTIE’SDELICATESSEN</s_store_name><s_store_addr>2290BROADWAY NewYork,NY10024</s_store_addr><s_line_items><s_item_value>16.95</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>SupremeBurger</s_item_name><s_item_key></s_item_key><sep/><s_item_value>15.25</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>Medium</s_item_name><s_item_key></s_item_key><sep/><s_item_value>2.25</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>PastramiBurger</s_item_name><s_item_key></s_item_key><sep/><s_item_value>4.50</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>Medium</s_item_name><s_item_key></s_item_key><sep/><s_item_value>5.50</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>fountainsoda</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>Clubsoda</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>CoffeeSMALL</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>SAMADAMS</s_item_name><s_item_key></s_item_key></s_line_items><s_ignore>    </s_ignore><s_date>3/15/2017</s_date></s_receipt>\\', \\'json\\': \\'{\"store_name\": \"ARTIE\\\\\\\\u2019SDELICATESSEN\", \"store_addr\": \"2290BROADWAY NewYork,NY10024\", \"telephone\": \"(212)579-5959\", \"date\": \"3/15/2017\", \"time\": \"7:43:29PM\", \"subtotal\": \"44.45\", \"tax\": \"3.95\", \"total\": \"$48.40\", \"ignore\": \"    \", \"tips\": \"\", \"line_items\": [{\"item_key\": \"\", \"item_name\": \"SupremeBurger\", \"item_value\": \"16.95\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Medium\", \"item_value\": \"15.25\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"PastramiBurger\", \"item_value\": \"2.25\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Medium\", \"item_value\": \"4.50\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"fountainsoda\", \"item_value\": \"5.50\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Clubsoda\", \"item_value\": \"\", \"item_quantity\": \"\"}, {\"item_key\": \"\", \"item_name\": \"CoffeeSMALL\", \"item_value\": \"\", \"item_quantity\": \"\"}, {\"item_key\": \"\", \"item_name\": \"SAMADAMS\", \"item_value\": \"\", \"item_quantity\": \"\"}]}\\', \\'kie\\': \"[{\\'label\\': \\'Store_name_value\\', \\'transcription\\': \\'ARTIE’SDELICATESSEN\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'2290BROADWAY\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'NewYork,NY10024\\'}, {\\'label\\': \\'Tel_value\\', \\'transcription\\': \\'(212)579-5959\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Server:Giovanna\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Station:4\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Order#:68771\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'DINEIN\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Table:41\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Guests:2\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'2\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'SupremeBurger\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Medium\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'PastramiBurger\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Medium\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'fountainsoda\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Clubsoda\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'CoffeeSMALL\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'SAMADAMS\\'}, {\\'label\\': \\'Subtotal_key\\', \\'transcription\\': \\'SUBTOTAL:\\'}, {\\'label\\': \\'Tax_key\\', \\'transcription\\': \\'SALESTAX(8.875%):\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'16.95\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'15.25\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'2.25\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'4.50\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'5.50\\'}, {\\'label\\': \\'Subtotal_value\\', \\'transcription\\': \\'44.45\\'}, {\\'label\\': \\'Tax_value\\', \\'transcription\\': \\'3.95\\'}, {\\'label\\': \\'Total_key\\', \\'transcription\\': \\'TOTAL:\\'}, {\\'label\\': \\'Total_value\\', \\'transcription\\': \\'$48.40\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'»Ticket#:95«\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Date_value\\', \\'transcription\\': \\'3/15/2017\\'}, {\\'label\\': \\'Time_value\\', \\'transcription\\': \\'7:43:29PM\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'THANKYOU!\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}]\"}\\n'),\n",
      " Document(metadata={'_id': '66fbb10d096d93b82a6ef726', 'id': '54'}, page_content='Invoice ID: 54\\nParsed Data: {\\'xml\\': \\'<s_receipt><s_total>$0.00</s_total><s_tips></s_tips><s_time>12:38:49PM</s_time><s_telephone>(800)275-8777</s_telephone><s_tax></s_tax><s_subtotal></s_subtotal><s_store_name>BOULEVARDSTATION</s_store_name><s_store_addr>BRONX,NewYork</s_store_addr><s_line_items><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name></s_item_name><s_item_key>Description</s_item_key></s_line_items><s_ignore></s_ignore><s_date>02/10/2015 2/10/2015</s_date></s_receipt>\\', \\'json\\': \\'{\"store_name\": \"BOULEVARDSTATION\", \"store_addr\": \"BRONX,NewYork\", \"telephone\": \"(800)275-8777\", \"date\": \"02/10/2015 2/10/2015\", \"time\": \"12:38:49PM\", \"subtotal\": \"\", \"tax\": \"\", \"total\": \"$0.00\", \"ignore\": \"\", \"tips\": \"\", \"line_items\": [{\"item_key\": \"Description\", \"item_name\": \"\", \"item_value\": \"\", \"item_quantity\": \"\"}]}\\', \\'kie\\': \"[{\\'label\\': \\'Store_name_value\\', \\'transcription\\': \\'BOULEVARDSTATION\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'BRONX,NewYork\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'104599998\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'3558250106-0095\\'}, {\\'label\\': \\'Time_value\\', \\'transcription\\': \\'12:38:49PM\\'}, {\\'label\\': \\'Date_value\\', \\'transcription\\': \\'02/10/2015\\'}, {\\'label\\': \\'Tel_value\\', \\'transcription\\': \\'(800)275-8777\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'SalesReceipt\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Product\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'SaleUnit\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Final\\'}, {\\'label\\': \\'Prod_price_key\\', \\'transcription\\': \\'Price\\'}, {\\'label\\': \\'Prod_quantity_key\\', \\'transcription\\': \\'Qty\\'}, {\\'label\\': \\'Prod_item_key\\', \\'transcription\\': \\'Description\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Pre-paidMaipieceAcceptance\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Price\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'2lbs.7.50oz.\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'EUCLID,OH44123\\'}, {\\'label\\': \\'Date_key\\', \\'transcription\\': \\'AcceptanceDate:\\'}, {\\'label\\': \\'Date_value\\', \\'transcription\\': \\'2/10/2015\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'12:38:46PM\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Label#:9405510899359043265827\\'}, {\\'label\\': \\'Total_key\\', \\'transcription\\': \\'Total:\\'}, {\\'label\\': \\'Total_value\\', \\'transcription\\': \\'$0.00\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Paidby:\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Orderstampsatusps.com/shopor\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'call1-800-Stamp24.Goto\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'usps.com/clicknshiptoprint\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}]\"}\\n'),\n",
      " Document(metadata={'_id': '66fbb10d096d93b82a6ef74f', 'id': '91'}, page_content='Invoice ID: 91\\nParsed Data: {\\'xml\\': \\'<s_receipt><s_total>$90.52 $90.52</s_total><s_tips></s_tips><s_time>1:11PM</s_time><s_telephone></s_telephone><s_tax>$9.00</s_tax><s_subtotal>$81.52</s_subtotal><s_store_name>AROMACAFE</s_store_name><s_store_addr>NewYork,NY 1211GreenStreet</s_store_addr><s_line_items><s_item_value>$6.75</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>CHOCCAKE</s_item_name><s_item_key></s_item_key><sep/><s_item_value>$11.50</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>WINE-GLASS-FIXE</s_item_name><s_item_key></s_item_key><sep/><s_item_value>$48.79</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>SURFANDTURF-1PERS</s_item_name><s_item_key></s_item_key><sep/><s_item_value>$7.69</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>HOUSESALAD</s_item_name><s_item_key></s_item_key><sep/><s_item_value>$6.79</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>GINGERCARROTSOUP</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name></s_item_name><s_item_key>DESC</s_item_key></s_line_items><s_ignore></s_ignore><s_date>03-12-2016</s_date></s_receipt>\\', \\'json\\': \\'{\"store_name\": \"AROMACAFE\", \"store_addr\": \"NewYork,NY 1211GreenStreet\", \"telephone\": \"\", \"date\": \"03-12-2016\", \"time\": \"1:11PM\", \"subtotal\": \"$81.52\", \"tax\": \"$9.00\", \"total\": \"$90.52 $90.52\", \"ignore\": \"\", \"tips\": \"\", \"line_items\": [{\"item_key\": \"\", \"item_name\": \"CHOCCAKE\", \"item_value\": \"$6.75\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"WINE-GLASS-FIXE\", \"item_value\": \"$11.50\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"SURFANDTURF-1PERS\", \"item_value\": \"$48.79\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"HOUSESALAD\", \"item_value\": \"$7.69\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"GINGERCARROTSOUP\", \"item_value\": \"$6.79\", \"item_quantity\": \"1\"}, {\"item_key\": \"DESC\", \"item_name\": \"\", \"item_value\": \"\", \"item_quantity\": \"\"}]}\\', \\'kie\\': \"[{\\'label\\': \\'Others\\', \\'transcription\\': \\'BALANCE\\'}, {\\'label\\': \\'Tax_key\\', \\'transcription\\': \\'TAX\\'}, {\\'label\\': \\'Subtotal_key\\', \\'transcription\\': \\'SUB-TOTAL\\'}, {\\'label\\': \\'Total_key\\', \\'transcription\\': \\'AMOUNT\\'}, {\\'label\\': \\'Total_value\\', \\'transcription\\': \\'$90.52\\'}, {\\'label\\': \\'Tax_value\\', \\'transcription\\': \\'$9.00\\'}, {\\'label\\': \\'Subtotal_value\\', \\'transcription\\': \\'$81.52\\'}, {\\'label\\': \\'Total_value\\', \\'transcription\\': \\'$90.52\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'CHOCCAKE\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'WINE-GLASS-FIXE\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'SURFANDTURF-1PERS\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'HOUSESALAD\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'GINGERCARROTSOUP\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'$6.75\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'$11.50\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'$48.79\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'$7.69\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'$6.79\\'}, {\\'label\\': \\'Prod_quantity_key\\', \\'transcription\\': \\'QTY\\'}, {\\'label\\': \\'Prod_item_key\\', \\'transcription\\': \\'DESC\\'}, {\\'label\\': \\'Prod_price_key\\', \\'transcription\\': \\'AMT\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'VISA######8281\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'TBL1\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'HOSTALISON\\'}, {\\'label\\': \\'Date_value\\', \\'transcription\\': \\'03-12-2016\\'}, {\\'label\\': \\'Time_value\\', \\'transcription\\': \\'1:11PM\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'NewYork,NY\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'1211GreenStreet\\'}, {\\'label\\': \\'Store_name_value\\', \\'transcription\\': \\'AROMACAFE\\'}]\"}\\n'),\n",
      " Document(metadata={'_id': '66fbb10d096d93b82a6ef739', 'id': '71'}, page_content='Invoice ID: 71\\nParsed Data: {\\'xml\\': \\'<s_receipt><s_total>$937.43 $937.43</s_total><s_tips></s_tips><s_time></s_time><s_telephone>516.683.8600</s_telephone><s_tax>$74.44</s_tax><s_subtotal>$862.99</s_subtotal><s_store_name>SportsAuthority#484</s_store_name><s_store_addr>1230OldCounryRoad Westbury,NY11590</s_store_addr><s_line_items><s_item_value>0.01</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>NEWBALANCE1500TRE20576899</s_item_name><s_item_key></s_item_key><sep/><s_item_value>62.99</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>DELIVERY/DELIVERYPR14551914</s_item_name><s_item_key></s_item_key><sep/><s_item_value>799.99</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>ASSEMBLY/TREADMILLS5239892</s_item_name><s_item_key></s_item_key></s_line_items><s_ignore>    </s_ignore><s_date></s_date></s_receipt>\\', \\'json\\': \\'{\"store_name\": \"SportsAuthority#484\", \"store_addr\": \"1230OldCounryRoad Westbury,NY11590\", \"telephone\": \"516.683.8600\", \"date\": \"\", \"time\": \"\", \"subtotal\": \"$862.99\", \"tax\": \"$74.44\", \"total\": \"$937.43 $937.43\", \"ignore\": \"    \", \"tips\": \"\", \"line_items\": [{\"item_key\": \"\", \"item_name\": \"NEWBALANCE1500TRE20576899\", \"item_value\": \"0.01\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"DELIVERY/DELIVERYPR14551914\", \"item_value\": \"62.99\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"ASSEMBLY/TREADMILLS5239892\", \"item_value\": \"799.99\", \"item_quantity\": \"1\"}]}\\', \\'kie\\': \"[{\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Store_name_value\\', \\'transcription\\': \\'SportsAuthority#484\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'1230OldCounryRoad\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'Westbury,NY11590\\'}, {\\'label\\': \\'Tel_value\\', \\'transcription\\': \\'516.683.8600\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'RAISEYOURGAME!\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'NEWBALANCE1500TRE20576899\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'REGULARPRICE\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'1099.99\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'DELIVERY/DELIVERYPR14551914\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'0.01\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'ASSEMBLY/TREADMILLS5239892\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'62.99\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'A\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'A\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Subtotal_key\\', \\'transcription\\': \\'SUBTOTAL\\'}, {\\'label\\': \\'Tax_key\\', \\'transcription\\': \\'A=8.625%SalesTax\\'}, {\\'label\\': \\'Total_key\\', \\'transcription\\': \\'TOTAL\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'MasterCard\\'}, {\\'label\\': \\'Subtotal_value\\', \\'transcription\\': \\'$862.99\\'}, {\\'label\\': \\'Tax_value\\', \\'transcription\\': \\'$74.44\\'}, {\\'label\\': \\'Total_value\\', \\'transcription\\': \\'$937.43\\'}, {\\'label\\': \\'Total_value\\', \\'transcription\\': \\'$937.43\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'A\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'p\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'799.99\\'}]\"}\\n')]\n"
     ]
    }
   ],
   "source": [
    "query = \"ARTIE'S DELICATESSEN, 2290 BROADWAY, New YorkNY 10024, 212579-5959\"\n",
    "results = vector_store.similarity_search(query)\n",
    "\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f8071",
   "metadata": {},
   "source": [
    "## Semamtic Search with Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff89caa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(metadata={'_id': '66fbb10d096d93b82a6ef714', 'id': '38'}, page_content='Invoice ID: 38\\nParsed Data: {\\'xml\\': \\'<s_receipt><s_total>$48.40</s_total><s_tips></s_tips><s_time>7:43:29PM</s_time><s_telephone>(212)579-5959</s_telephone><s_tax>3.95</s_tax><s_subtotal>44.45</s_subtotal><s_store_name>ARTIE’SDELICATESSEN</s_store_name><s_store_addr>2290BROADWAY NewYork,NY10024</s_store_addr><s_line_items><s_item_value>16.95</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>SupremeBurger</s_item_name><s_item_key></s_item_key><sep/><s_item_value>15.25</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>Medium</s_item_name><s_item_key></s_item_key><sep/><s_item_value>2.25</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>PastramiBurger</s_item_name><s_item_key></s_item_key><sep/><s_item_value>4.50</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>Medium</s_item_name><s_item_key></s_item_key><sep/><s_item_value>5.50</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>fountainsoda</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>Clubsoda</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>CoffeeSMALL</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>SAMADAMS</s_item_name><s_item_key></s_item_key></s_line_items><s_ignore>    </s_ignore><s_date>3/15/2017</s_date></s_receipt>\\', \\'json\\': \\'{\"store_name\": \"ARTIE\\\\\\\\u2019SDELICATESSEN\", \"store_addr\": \"2290BROADWAY NewYork,NY10024\", \"telephone\": \"(212)579-5959\", \"date\": \"3/15/2017\", \"time\": \"7:43:29PM\", \"subtotal\": \"44.45\", \"tax\": \"3.95\", \"total\": \"$48.40\", \"ignore\": \"    \", \"tips\": \"\", \"line_items\": [{\"item_key\": \"\", \"item_name\": \"SupremeBurger\", \"item_value\": \"16.95\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Medium\", \"item_value\": \"15.25\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"PastramiBurger\", \"item_value\": \"2.25\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Medium\", \"item_value\": \"4.50\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"fountainsoda\", \"item_value\": \"5.50\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Clubsoda\", \"item_value\": \"\", \"item_quantity\": \"\"}, {\"item_key\": \"\", \"item_name\": \"CoffeeSMALL\", \"item_value\": \"\", \"item_quantity\": \"\"}, {\"item_key\": \"\", \"item_name\": \"SAMADAMS\", \"item_value\": \"\", \"item_quantity\": \"\"}]}\\', \\'kie\\': \"[{\\'label\\': \\'Store_name_value\\', \\'transcription\\': \\'ARTIE’SDELICATESSEN\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'2290BROADWAY\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'NewYork,NY10024\\'}, {\\'label\\': \\'Tel_value\\', \\'transcription\\': \\'(212)579-5959\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Server:Giovanna\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Station:4\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Order#:68771\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'DINEIN\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Table:41\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Guests:2\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'2\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'SupremeBurger\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Medium\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'PastramiBurger\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Medium\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'fountainsoda\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Clubsoda\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'CoffeeSMALL\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'SAMADAMS\\'}, {\\'label\\': \\'Subtotal_key\\', \\'transcription\\': \\'SUBTOTAL:\\'}, {\\'label\\': \\'Tax_key\\', \\'transcription\\': \\'SALESTAX(8.875%):\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'16.95\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'15.25\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'2.25\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'4.50\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'5.50\\'}, {\\'label\\': \\'Subtotal_value\\', \\'transcription\\': \\'44.45\\'}, {\\'label\\': \\'Tax_value\\', \\'transcription\\': \\'3.95\\'}, {\\'label\\': \\'Total_key\\', \\'transcription\\': \\'TOTAL:\\'}, {\\'label\\': \\'Total_value\\', \\'transcription\\': \\'$48.40\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'»Ticket#:95«\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Date_value\\', \\'transcription\\': \\'3/15/2017\\'}, {\\'label\\': \\'Time_value\\', \\'transcription\\': \\'7:43:29PM\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'THANKYOU!\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}]\"}\\n'),\n",
      "  0.6575489044189453)]\n"
     ]
    }
   ],
   "source": [
    "# query = \"Patel, Thompson and Montgomery 356 Kyle Vista New James, MA 46228\"\n",
    "query = \"ARTIE'S DELICATESSEN, 2290 BROADWAY, New YorkNY 10024, 212579-5959\"\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    query = query,\n",
    "    k = 1,\n",
    "    pre_filter = { \"id\": { \"$in\": [\"38\"] } }\n",
    ")\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c2245",
   "metadata": {},
   "source": [
    "## Llama.cpp\n",
    "In this experiment I am using Llama.cpp model to run `Llama-3.2-3B-Instruct` 100% locally on a Macbook Pro.\n",
    "You can of course use the original model (not quantized) directly via HuggingFace Transformers if you have a powerful GPU at your disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264159b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\",\n",
    "    filename=\"*q8_0.gguf\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5541e6be",
   "metadata": {},
   "source": [
    "## Basic RAG\n",
    "\n",
    "This example does the following:\n",
    "\n",
    "- Instantiates Atlas Vector Search as a retriever to query for similar documents, including the optional k parameter to search for only the 10 most relevant documents.\n",
    "\n",
    "- Defines a LangChain prompt template to instruct the LLM to use these documents as context for your query. LangChain passes these documents to the {context} input variable and your query to the {question} variable.\n",
    "\n",
    "- Constructs a chain that specifies the following:\n",
    "\n",
    "  - Atlas Vector Search as the retriever to search for documents that are used as context by the LLM.\n",
    "\n",
    "  - The prompt template that you constructed.\n",
    "\n",
    "  - `llama-3.2-3b-instruct` model as the LLM used to generate a context-aware response.\n",
    "\n",
    "- Prompts the chain with a sample query about Atlas security recommendations.\n",
    "\n",
    "- Returns the LLM's response and the documents used as context. The generated response might vary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "740ddf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file (create this file in your project directory)\n",
    "load_dotenv()\n",
    "\n",
    "# Get the model directory from environment variables\n",
    "model_dir = os.getenv('LLAMA_MODEL_DIR')\n",
    "model_file = os.getenv('LLAMA_MODEL_FILE', 'llama-3.2-3b-instruct-q8_0.gguf')\n",
    "\n",
    "if not model_dir:\n",
    "    raise ValueError(\"LLAMA_MODEL_DIR environment variable is not set\")\n",
    "\n",
    "model_path = os.path.join(model_dir, model_file)\n",
    "\n",
    "# Rest of your code remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bd866d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 30 key-value pairs and 255 tensors from /Users/sina/.cache/huggingface/hub/models--hugging-quants--Llama-3.2-3B-Instruct-Q8_0-GGUF/snapshots/7ef7efff7d2c14e5d6161a0c7006e1f2fea6ec79/llama-3.2-3b-instruct-q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Llama-3.2\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 3B\n",
      "llama_model_loader: - kv   6:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   7:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   8:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   9:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  10:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  11:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  12:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  13:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  14:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  15:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  16:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  17:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  18:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  19:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  20:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  21:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  22:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  25:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q8_0:  197 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_layer          = 28\n",
      "llm_load_print_meta: n_head           = 24\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 3\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = ?B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 3.21 B\n",
      "llm_load_print_meta: model size       = 3.18 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = Llama 3.2 3B Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.12 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/29 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  3255.90 MiB\n",
      ".................................................................................\n",
      "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
      "llama_new_context_with_model: n_ctx      = 8192\n",
      "llama_new_context_with_model: n_batch    = 32\n",
      "llama_new_context_with_model: n_ubatch   = 8\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   896.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  896.00 MiB, K (f16):  448.00 MiB, V (f16):  448.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     7.38 MiB\n",
      "llama_new_context_with_model: graph nodes  = 902\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\", 'tokenizer.ggml.eos_token_id': '128009', 'general.type': 'model', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.model': 'gpt2', 'llama.embedding_length': '3072', 'llama.vocab_size': '128256', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.attention.value_length': '128', 'llama.attention.head_count': '24', 'llama.attention.key_length': '128', 'llama.attention.head_count_kv': '8', 'llama.context_length': '131072', 'general.finetune': 'Instruct', 'general.file_type': '7', 'llama.block_count': '28', 'general.size_label': '3B', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.architecture': 'llama', 'general.basename': 'Llama-3.2', 'general.quantization_version': '2', 'llama.rope.dimension_count': '128', 'llama.rope.freq_base': '500000.000000', 'general.name': 'Llama 3.2 3B Instruct'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "llama_perf_context_print:        load time =   59444.81 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1598 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   157 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   67630.16 ms /  1755 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\u001b[1m\u001b[36mQuestion:\u001b[0m\n",
      "\u001b[36mWhat is the store address of the store with name 'ARTIE'S DELICATESSEN'?\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[32mAnswer:\u001b[0m\n",
      "\u001b[32mThe store address is '2290BROADWAY NewYork,NY10024'. \n",
      "\n",
      "Note: The provided data is in XML format. To answer the question, we need to parse the XML data and extract the required information. \n",
      "\n",
      "Here's a sample Python code snippet that demonstrates how to parse the XML data using the `xml.etree.ElementTree` module:\n",
      "\n",
      "```python\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "# Parse the XML data\n",
      "root = ET.fromstring(xml_data)\n",
      "\n",
      "# Extract the store address\n",
      "store_addr = root.find('.//s_store_addr').text\n",
      "\n",
      "print(store_addr)\n",
      "```\n",
      "\n",
      "Note that this code snippet assumes that the `xml_data` variable contains the parsed XML data. You may need to modify the code to match your specific use case.\u001b[0m\n",
      "==================================================\n",
      "\n",
      "\n",
      "Source documents:\n",
      "[Document(metadata={'_id': '66fbb10d096d93b82a6ef714', 'id': '38'}, page_content='Invoice ID: 38\\nParsed Data: {\\'xml\\': \\'<s_receipt><s_total>$48.40</s_total><s_tips></s_tips><s_time>7:43:29PM</s_time><s_telephone>(212)579-5959</s_telephone><s_tax>3.95</s_tax><s_subtotal>44.45</s_subtotal><s_store_name>ARTIE’SDELICATESSEN</s_store_name><s_store_addr>2290BROADWAY NewYork,NY10024</s_store_addr><s_line_items><s_item_value>16.95</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>SupremeBurger</s_item_name><s_item_key></s_item_key><sep/><s_item_value>15.25</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>Medium</s_item_name><s_item_key></s_item_key><sep/><s_item_value>2.25</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>PastramiBurger</s_item_name><s_item_key></s_item_key><sep/><s_item_value>4.50</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>Medium</s_item_name><s_item_key></s_item_key><sep/><s_item_value>5.50</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>fountainsoda</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>Clubsoda</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>CoffeeSMALL</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>SAMADAMS</s_item_name><s_item_key></s_item_key></s_line_items><s_ignore>    </s_ignore><s_date>3/15/2017</s_date></s_receipt>\\', \\'json\\': \\'{\"store_name\": \"ARTIE\\\\\\\\u2019SDELICATESSEN\", \"store_addr\": \"2290BROADWAY NewYork,NY10024\", \"telephone\": \"(212)579-5959\", \"date\": \"3/15/2017\", \"time\": \"7:43:29PM\", \"subtotal\": \"44.45\", \"tax\": \"3.95\", \"total\": \"$48.40\", \"ignore\": \"    \", \"tips\": \"\", \"line_items\": [{\"item_key\": \"\", \"item_name\": \"SupremeBurger\", \"item_value\": \"16.95\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Medium\", \"item_value\": \"15.25\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"PastramiBurger\", \"item_value\": \"2.25\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Medium\", \"item_value\": \"4.50\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"fountainsoda\", \"item_value\": \"5.50\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Clubsoda\", \"item_value\": \"\", \"item_quantity\": \"\"}, {\"item_key\": \"\", \"item_name\": \"CoffeeSMALL\", \"item_value\": \"\", \"item_quantity\": \"\"}, {\"item_key\": \"\", \"item_name\": \"SAMADAMS\", \"item_value\": \"\", \"item_quantity\": \"\"}]}\\', \\'kie\\': \"[{\\'label\\': \\'Store_name_value\\', \\'transcription\\': \\'ARTIE’SDELICATESSEN\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'2290BROADWAY\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'NewYork,NY10024\\'}, {\\'label\\': \\'Tel_value\\', \\'transcription\\': \\'(212)579-5959\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Server:Giovanna\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Station:4\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Order#:68771\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'DINEIN\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Table:41\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Guests:2\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'2\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'SupremeBurger\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Medium\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'PastramiBurger\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Medium\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'fountainsoda\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Clubsoda\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'CoffeeSMALL\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'SAMADAMS\\'}, {\\'label\\': \\'Subtotal_key\\', \\'transcription\\': \\'SUBTOTAL:\\'}, {\\'label\\': \\'Tax_key\\', \\'transcription\\': \\'SALESTAX(8.875%):\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'16.95\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'15.25\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'2.25\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'4.50\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'5.50\\'}, {\\'label\\': \\'Subtotal_value\\', \\'transcription\\': \\'44.45\\'}, {\\'label\\': \\'Tax_value\\', \\'transcription\\': \\'3.95\\'}, {\\'label\\': \\'Total_key\\', \\'transcription\\': \\'TOTAL:\\'}, {\\'label\\': \\'Total_value\\', \\'transcription\\': \\'$48.40\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'»Ticket#:95«\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Date_value\\', \\'transcription\\': \\'3/15/2017\\'}, {\\'label\\': \\'Time_value\\', \\'transcription\\': \\'7:43:29PM\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'THANKYOU!\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}]\"}\\n')]\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "from llama_cpp import Llama\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "\n",
    "model_path = os.path.join(model_dir, model_file)\n",
    "\n",
    "# Instantiate the Vector Search as a Retriever\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type = \"similarity\",\n",
    "    search_kwargs = { \"k\": 1 }\n",
    ")\n",
    "\n",
    "# Define a prompt template\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Custom callback handler to capture output\n",
    "class CaptureOutputHandler(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.output = \"\"\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.output += token\n",
    "\n",
    "# Set up the Llama model\n",
    "capture_handler = CaptureOutputHandler()\n",
    "callback_manager = CallbackManager([capture_handler])\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=model_path,\n",
    "    temperature=0,\n",
    "    max_tokens=2000,\n",
    "    top_p=1,\n",
    "    n_ctx=8192,  # Increase this value, try 4096 or 8192\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        formatted_doc = f\"Invoice ID: {doc.metadata['id']}\\n\"\n",
    "        formatted_doc += f\"Content: {doc.page_content}\\n\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "    return \"\\n\\n\".join(formatted_docs[:3])\n",
    "\n",
    "# Construct a chain to answer questions on your data\n",
    "rag_chain = (\n",
    "    { \"context\": retriever | format_docs, \"question\": RunnablePassthrough() }\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Prompt the chain with a query\n",
    "question = \"What is the store address of the store with name 'ARTIE'S DELICATESSEN'?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "# Print question and answer with distinct formatting\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(colored(\"Question:\", \"cyan\", attrs=[\"bold\"]))\n",
    "print(colored(question, \"cyan\"))\n",
    "print(\"\\n\" + colored(\"Answer:\", \"green\", attrs=[\"bold\"]))\n",
    "print(colored(answer.strip(), \"green\"))\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Return source documents\n",
    "documents = retriever.invoke(question)\n",
    "print(\"\\nSource documents:\")\n",
    "pprint.pprint(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc6c16",
   "metadata": {},
   "source": [
    "## RAG with Filtering\n",
    "\n",
    "This example does the following:\n",
    "\n",
    "- Instantiates Atlas Vector Search as a retriever to query for similar documents, including the following optional parameters:\n",
    "\n",
    "  - `k` to search for only the `5` most relevant documents.\n",
    "\n",
    "  - `score_threshold` to use only documents with a relevance score above `0.1`.\n",
    "\n",
    "    - Note\n",
    "    This parameter refers to a relevance score that Langchain uses to normalize your results, and not the relevance score used in Atlas Search queries. To use Atlas Search scores in your RAG implementation, define a custom retriever that uses the similarity_search_with_score method and filters by the Atlas Search score.\n",
    "\n",
    "  - `pre_filter` to filter on the  `id` field for documents that appear with id `0` only.\n",
    "\n",
    "- Defines a LangChain prompt template to instruct the LLM to use these documents as context for your query. LangChain passes these documents to the  `{context}` input variable and your query to the `{question}` variable.\n",
    "\n",
    "- Constructs a chain that specifies the following:\n",
    "\n",
    "  - Atlas Vector Search as the retriever to search for documents that are used as context by the LLM.\n",
    "\n",
    "  - The prompt template that you constructed.\n",
    "\n",
    "  - `llama-3.2-3b-instruct` model as the LLM used to generate a context-aware response.\n",
    "\n",
    "- Prompts the chain with a sample query about Atlas security recommendations.\n",
    "\n",
    "- Returns the LLM's response and the documents used as context. The generated response might vary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "affb9e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 30 key-value pairs and 255 tensors from /Users/sina/.cache/huggingface/hub/models--hugging-quants--Llama-3.2-3B-Instruct-Q8_0-GGUF/snapshots/7ef7efff7d2c14e5d6161a0c7006e1f2fea6ec79/llama-3.2-3b-instruct-q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Llama-3.2\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 3B\n",
      "llama_model_loader: - kv   6:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   7:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   8:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   9:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  10:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  11:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  12:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  13:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  14:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  15:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  16:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  17:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  18:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  19:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  20:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  21:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  22:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  25:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q8_0:  197 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_layer          = 28\n",
      "llm_load_print_meta: n_head           = 24\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 3\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = ?B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 3.21 B\n",
      "llm_load_print_meta: model size       = 3.18 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = Llama 3.2 3B Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.12 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/29 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  3255.90 MiB\n",
      ".................................................................................\n",
      "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
      "llama_new_context_with_model: n_ctx      = 8192\n",
      "llama_new_context_with_model: n_batch    = 32\n",
      "llama_new_context_with_model: n_ubatch   = 8\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   896.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  896.00 MiB, K (f16):  448.00 MiB, V (f16):  448.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     7.38 MiB\n",
      "llama_new_context_with_model: graph nodes  = 902\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\", 'tokenizer.ggml.eos_token_id': '128009', 'general.type': 'model', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.model': 'gpt2', 'llama.embedding_length': '3072', 'llama.vocab_size': '128256', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.attention.value_length': '128', 'llama.attention.head_count': '24', 'llama.attention.key_length': '128', 'llama.attention.head_count_kv': '8', 'llama.context_length': '131072', 'general.finetune': 'Instruct', 'general.file_type': '7', 'llama.block_count': '28', 'general.size_label': '3B', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.architecture': 'llama', 'general.basename': 'Llama-3.2', 'general.quantization_version': '2', 'llama.rope.dimension_count': '128', 'llama.rope.freq_base': '500000.000000', 'general.name': 'Llama 3.2 3B Instruct'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "llama_perf_context_print:        load time =   64599.42 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1598 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   157 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   72942.58 ms /  1755 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\u001b[1m\u001b[36mQuestion:\u001b[0m\n",
      "\u001b[36mWhat is the store address of the store with name 'ARTIE'S DELICATESSEN'?\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[32mAnswer:\u001b[0m\n",
      "\u001b[32mThe store address is '2290BROADWAY NewYork,NY10024'. \n",
      "\n",
      "Note: The provided data is in XML format. To answer the question, we need to parse the XML data and extract the required information. \n",
      "\n",
      "Here's a sample Python code snippet that demonstrates how to parse the XML data using the `xml.etree.ElementTree` module:\n",
      "\n",
      "```python\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "# Parse the XML data\n",
      "root = ET.fromstring(xml_data)\n",
      "\n",
      "# Extract the store address\n",
      "store_addr = root.find('.//s_store_addr').text\n",
      "\n",
      "print(store_addr)\n",
      "```\n",
      "\n",
      "Note that this code snippet assumes that the `xml_data` variable contains the parsed XML data. You may need to modify the code to match your specific use case.\u001b[0m\n",
      "==================================================\n",
      "\n",
      "\n",
      "Source documents:\n",
      "[Document(metadata={'_id': '66fbb10d096d93b82a6ef714', 'id': '38'}, page_content='Invoice ID: 38\\nParsed Data: {\\'xml\\': \\'<s_receipt><s_total>$48.40</s_total><s_tips></s_tips><s_time>7:43:29PM</s_time><s_telephone>(212)579-5959</s_telephone><s_tax>3.95</s_tax><s_subtotal>44.45</s_subtotal><s_store_name>ARTIE’SDELICATESSEN</s_store_name><s_store_addr>2290BROADWAY NewYork,NY10024</s_store_addr><s_line_items><s_item_value>16.95</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>SupremeBurger</s_item_name><s_item_key></s_item_key><sep/><s_item_value>15.25</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>Medium</s_item_name><s_item_key></s_item_key><sep/><s_item_value>2.25</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>PastramiBurger</s_item_name><s_item_key></s_item_key><sep/><s_item_value>4.50</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>Medium</s_item_name><s_item_key></s_item_key><sep/><s_item_value>5.50</s_item_value><s_item_quantity>1</s_item_quantity><s_item_name>fountainsoda</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>Clubsoda</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>CoffeeSMALL</s_item_name><s_item_key></s_item_key><sep/><s_item_value></s_item_value><s_item_quantity></s_item_quantity><s_item_name>SAMADAMS</s_item_name><s_item_key></s_item_key></s_line_items><s_ignore>    </s_ignore><s_date>3/15/2017</s_date></s_receipt>\\', \\'json\\': \\'{\"store_name\": \"ARTIE\\\\\\\\u2019SDELICATESSEN\", \"store_addr\": \"2290BROADWAY NewYork,NY10024\", \"telephone\": \"(212)579-5959\", \"date\": \"3/15/2017\", \"time\": \"7:43:29PM\", \"subtotal\": \"44.45\", \"tax\": \"3.95\", \"total\": \"$48.40\", \"ignore\": \"    \", \"tips\": \"\", \"line_items\": [{\"item_key\": \"\", \"item_name\": \"SupremeBurger\", \"item_value\": \"16.95\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Medium\", \"item_value\": \"15.25\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"PastramiBurger\", \"item_value\": \"2.25\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Medium\", \"item_value\": \"4.50\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"fountainsoda\", \"item_value\": \"5.50\", \"item_quantity\": \"1\"}, {\"item_key\": \"\", \"item_name\": \"Clubsoda\", \"item_value\": \"\", \"item_quantity\": \"\"}, {\"item_key\": \"\", \"item_name\": \"CoffeeSMALL\", \"item_value\": \"\", \"item_quantity\": \"\"}, {\"item_key\": \"\", \"item_name\": \"SAMADAMS\", \"item_value\": \"\", \"item_quantity\": \"\"}]}\\', \\'kie\\': \"[{\\'label\\': \\'Store_name_value\\', \\'transcription\\': \\'ARTIE’SDELICATESSEN\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'2290BROADWAY\\'}, {\\'label\\': \\'Store_addr_value\\', \\'transcription\\': \\'NewYork,NY10024\\'}, {\\'label\\': \\'Tel_value\\', \\'transcription\\': \\'(212)579-5959\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Server:Giovanna\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Station:4\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Order#:68771\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'DINEIN\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Table:41\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'Guests:2\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'2\\'}, {\\'label\\': \\'Prod_quantity_value\\', \\'transcription\\': \\'1\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'SupremeBurger\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Medium\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'PastramiBurger\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Medium\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'fountainsoda\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'Clubsoda\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'CoffeeSMALL\\'}, {\\'label\\': \\'Prod_item_value\\', \\'transcription\\': \\'SAMADAMS\\'}, {\\'label\\': \\'Subtotal_key\\', \\'transcription\\': \\'SUBTOTAL:\\'}, {\\'label\\': \\'Tax_key\\', \\'transcription\\': \\'SALESTAX(8.875%):\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'16.95\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'15.25\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'2.25\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'4.50\\'}, {\\'label\\': \\'Prod_price_value\\', \\'transcription\\': \\'5.50\\'}, {\\'label\\': \\'Subtotal_value\\', \\'transcription\\': \\'44.45\\'}, {\\'label\\': \\'Tax_value\\', \\'transcription\\': \\'3.95\\'}, {\\'label\\': \\'Total_key\\', \\'transcription\\': \\'TOTAL:\\'}, {\\'label\\': \\'Total_value\\', \\'transcription\\': \\'$48.40\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'»Ticket#:95«\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Date_value\\', \\'transcription\\': \\'3/15/2017\\'}, {\\'label\\': \\'Time_value\\', \\'transcription\\': \\'7:43:29PM\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Others\\', \\'transcription\\': \\'THANKYOU!\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}, {\\'label\\': \\'Ignore\\', \\'transcription\\': \\'\\'}]\"}\\n')]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Vector Search as a Retriever\n",
    "retriever = vector_store.as_retriever(\n",
    "   search_type = \"similarity_score_threshold\",\n",
    "   search_kwargs = {\n",
    "      \"k\": 5,\n",
    "      \"score_threshold\": 0.1,\n",
    "      \"pre_filter\": { \"id\": { \"$in\": [\"38\"] } }\n",
    "   }\n",
    ")\n",
    "\n",
    "# Define a prompt template\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Custom callback handler to capture output\n",
    "class CaptureOutputHandler(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.output = \"\"\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.output += token\n",
    "\n",
    "# Set up the Llama model\n",
    "capture_handler = CaptureOutputHandler()\n",
    "callback_manager = CallbackManager([capture_handler])\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=model_path,\n",
    "    temperature=0,\n",
    "    max_tokens=2000,\n",
    "    top_p=1,\n",
    "    n_ctx=8192,  # Increase this value, try 4096 or 8192\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        formatted_doc = f\"Invoice ID: {doc.metadata['id']}\\n\"\n",
    "        formatted_doc += f\"Content: {doc.page_content}\\n\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "    return \"\\n\\n\".join(formatted_docs[:3])\n",
    "\n",
    "# Construct a chain to answer questions on your data\n",
    "rag_chain = (\n",
    "    { \"context\": retriever | format_docs, \"question\": RunnablePassthrough() }\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Prompt the chain with a query\n",
    "question = \"What is the store address of the store with name 'ARTIE'S DELICATESSEN'?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "# Print question and answer with distinct formatting\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(colored(\"Question:\", \"cyan\", attrs=[\"bold\"]))\n",
    "print(colored(question, \"cyan\"))\n",
    "print(\"\\n\" + colored(\"Answer:\", \"green\", attrs=[\"bold\"]))\n",
    "print(colored(answer.strip(), \"green\"))\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Return source documents\n",
    "documents = retriever.invoke(question)\n",
    "print(\"\\nSource documents:\")\n",
    "pprint.pprint(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_rag_env",
   "language": "python",
   "name": "llama_rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
