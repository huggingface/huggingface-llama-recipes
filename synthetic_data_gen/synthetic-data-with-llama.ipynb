{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCBXqkAbYJO0"
      },
      "source": [
        "# ğŸ¦™ âš—ï¸ Synthetic data generation with Llama 3.1 405B and distilabel\n",
        "\n",
        "This notebook shows how to generate synthetic datasets using the new Llama 3.1 models using [distilabel](https://github.com/argilla-io/distilabel), an open-source framework for synthetic data generation.\n",
        "\n",
        "Thanks to the new 3.1 license, you can now build synthetic datasets to fine-tune smaller, more specialized models using the larger 405B and 70B Llama models.\n",
        "\n",
        "Synthetic data generation is a broad topic and there's many exciting developments and libraries coming out in the past months. distilabel enables you to implement end-to-end data generation pipelines, covering different stages and use cases, such as:\n",
        "\n",
        "- [Generating](https://distilabel.argilla.io/latest/components-gallery/tasks/genstruct/) and [evolving instructions](https://distilabel.argilla.io/latest/components-gallery/tasks/evolinstruct/).\n",
        "- [Generating and selecting data](https://distilabel.argilla.io/latest/sections/pipeline_samples/papers/deita/?h=deita) for supervised fine tuning.\n",
        "- Rating responses for [preference tuning](https://distilabel.argilla.io/latest/components-gallery/tasks/ultrafeedback/?h=ultrafeedback) with [LLM-as-a-judge methods](https://distilabel.argilla.io/latest/components-gallery/tasks/prometheuseval/?h=prometheus).\n",
        "\n",
        "In this notebook, you'll learn the basics of distilabel by generating a preference dataset from scratch using Hugging Face Inference Endpoints. Besides Inference Endpoints, distilabel provides many [out-of-the-box options](https://distilabel.argilla.io/latest/components-gallery/llms/) for running LLM inference, from running local models to using inference providers.\n",
        "\n",
        "Let's get started ğŸš€\n",
        "## Install distilabel\n",
        "First you need to install distilabel and the inference endpoints dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wKHzsPsFLYo8",
        "outputId": "0ffac1ff-3b23-4955-891e-c0a710ef0d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m290.9/290.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install distilabel[hf-inference-endpoints] -U -qqq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvG5SRuTZ6o8"
      },
      "source": [
        "## Login Hugging Face Hub\n",
        "\n",
        "You need to login to be able to use Inference Endpoints. You should use a token with enough rights to run Inference endpoints. If you don't have a token, you can generate one [here](https://huggingface.co/settings/tokens)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "fceafd6471364cf7a3084f8b4df69fdd",
            "31c731c8754747169c4c12810f7581f5",
            "76bb535338424f36b2e183d45264c5e2",
            "235485e2ceae48b5ad74041b137ec894",
            "aecd2c76f1de4cacad538e8eafa0866d",
            "20dc723717b348eb85b7e48d39cecbab",
            "7f56bae1e921469cb12ce02f8a0d36b8",
            "2068afbcad714221a55a9255e9059ee7",
            "c5de62cf1901423ea8c18100210ea3c7",
            "6eeb7762809c479a84927ea52e729825",
            "0b7d513bd8884f919c565aaf5e69e986",
            "0d0f4e3b92f14918a5ac82dc898c3083",
            "715d2b367ceb4e84ae7f8859454f17b6",
            "04f647b1b21e4a10896440a21e81a7ac",
            "6f9f650f11104badaded5e493c11bec6",
            "601141c9ebff44ffaf64d6b8b77575ce",
            "b8f6c5d693d744289b6275913523d08f",
            "ae935b27bf8742a09985259a67377ccc",
            "6ad19c9a2ec44f66ad5b0a6a337123a7",
            "89f4e4bc90a74280b2533f5e36563464",
            "a3b428795ce849208b4583bfd88f54fa",
            "2455b9373b324c2b837097f241419034",
            "37b0eade00b94af8bc7b890ea6135d12",
            "7a177492a4b1496985892ffc377a23d9",
            "009b1d2a829d4e31b651f67ccb1f1d9f",
            "ae98e8056275444883649e62299ee6ab",
            "bc8819a425c24f97a5e54ec8e2e1a8e2",
            "af498a88d197460eb2755358c5986d3e",
            "b33356e1bdb14ae88e446d2a4395a023",
            "be4fb65648a949bda9831cf0dee42482",
            "17eb2bcf26404cd5b326dda6553bfd03",
            "ab96b9564f6347af93acd10d846750bb"
          ]
        },
        "id": "ci5Nok9jZ_8G",
        "outputId": "2dc9c199-2efc-495e-cf93-bd0c0ba76e37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fceafd6471364cf7a3084f8b4df69fdd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RWPg572aDIc"
      },
      "source": [
        "## Quickstart\n",
        "\n",
        "Let's start with a quick example: a pipeline to build a preference dataset with the following steps:\n",
        "\n",
        "- Load a dataset with instructions from the Hugging Face Hub using the `LoadDataFromHub` [step](https://distilabel.argilla.io/latest/components-gallery/steps/loaddatafromhub/).\n",
        "- For each prompt, generate two responses using the `TextGeneration` task with the `InferenceEndpointsLLM` [LLM](https://distilabel.argilla.io/latest/components-gallery/llms/inferenceendpointsllm/) and the 405B and 70B models.\n",
        "- Combine the two responses into a list of responses using the `CombineColumns` [step](https://distilabel.argilla.io/latest/components-gallery/steps/combinecolumns/).\n",
        "- Compare and rate the responses using the `UltraFeedback` [llm-as-a-judge task](https://distilabel.argilla.io/latest/components-gallery/tasks/ultrafeedback/) with the 405B model.\n",
        "\n",
        "See below the input dataset with instructions. The pipeline will use the `instruction` column to generate responses with Llama 3.1 models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "0PA4cVMSz0NG",
        "outputId": "5083025f-0ee6-433e-d326-b076681dbffe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<iframe src=\"https://huggingface.co/datasets/argilla/10Kprompts-mini/embed/viewer/train\" width=\"80%\" height=\"560px\"></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "iframe_html = \"\"\"\n",
        "<iframe src=\"https://huggingface.co/datasets/argilla/10Kprompts-mini/embed/viewer/train\" width=\"80%\" height=\"560px\"></iframe>\n",
        "\"\"\"\n",
        "display(HTML(iframe_html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hE3-qC106lV"
      },
      "source": [
        "Now let's run the pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIa06xswLi_9"
      },
      "outputs": [],
      "source": [
        "from distilabel.llms import InferenceEndpointsLLM\n",
        "from distilabel.pipeline import Pipeline\n",
        "from distilabel.steps import LoadDataFromHub\n",
        "from distilabel.steps.tasks import TextGeneration, UltraFeedback\n",
        "from distilabel.steps import CombineColumns\n",
        "\n",
        "llama70B = InferenceEndpointsLLM(\n",
        "    model_id=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
        ")\n",
        "llama405B = InferenceEndpointsLLM(\n",
        "    model_id=\"meta-llama/Meta-Llama-3.1-405B-Instruct-FP8\",\n",
        ")\n",
        "\n",
        "with Pipeline(name=\"synthetic-data-with-llama3\") as pipeline:\n",
        "\n",
        "    # load dataset with prompts\n",
        "    load_dataset = LoadDataFromHub(\n",
        "        repo_id= \"argilla/10Kprompts-mini\"\n",
        "    )\n",
        "\n",
        "    # generate two responses\n",
        "    generate = [\n",
        "        TextGeneration(llm=llama70B),\n",
        "        TextGeneration(llm=llama405B)\n",
        "    ]\n",
        "\n",
        "    # combine responses into one col\n",
        "    combine = CombineColumns(\n",
        "        columns=[\"generation\", \"model_name\"],\n",
        "        output_columns=[\"generations\", \"model_names\"]\n",
        "    )\n",
        "\n",
        "    # rate responses with 405B LLM-as-a-judge\n",
        "    rate = UltraFeedback(aspect=\"overall-rating\", llm=llama405B)\n",
        "\n",
        "    # define and run pipeline\n",
        "    load_dataset >> generate >> combine >> rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYPLlgDgHNp2"
      },
      "outputs": [],
      "source": [
        "distiset = pipeline.run(use_cache=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "bmSW3jXIHVL8",
        "outputId": "200faab4-2255-457c-b2a5-7ee06f0f88b1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"distiset['default']['train']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Is it possible to convert DC welding machine to plasma cutter ?\",\n          \"If a particular argument hinges on an anecdotal evidence, how might that impact the strength of the conclusion?\",\n          \"Delete a part of the sentence that does not fit the context.\\nHe likes to run and painting his house.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Literature and Arts\",\n          \"Others\",\n          \"Science and Technology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generations\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distilabel_metadata\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_names\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ratings\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rationales\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"sllhf/Meta-Llama-3.1-405B-Instruct-FP8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-29a1018d-155b-4dd2-b551-a0a946c95be8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>topic</th>\n",
              "      <th>generations</th>\n",
              "      <th>distilabel_metadata</th>\n",
              "      <th>model_names</th>\n",
              "      <th>ratings</th>\n",
              "      <th>rationales</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How can I create an efficient and robust workf...</td>\n",
              "      <td>Software Development</td>\n",
              "      <td>[To create an efficient and robust workflow th...</td>\n",
              "      <td>{'raw_output_ultra_feedback_0': '#### Output f...</td>\n",
              "      <td>[llhf/Meta-Llama-3.1-70B-Instruct, sllhf/Meta-...</td>\n",
              "      <td>[5.0, 1.0]</td>\n",
              "      <td>[The output provides a clear, step-by-step gui...</td>\n",
              "      <td>sllhf/Meta-Llama-3.1-405B-Instruct-FP8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is it possible to convert DC welding machine t...</td>\n",
              "      <td>Literature and Arts</td>\n",
              "      <td>[While it's technically possible to modify a D...</td>\n",
              "      <td>{'raw_output_ultra_feedback_0': '#### Output f...</td>\n",
              "      <td>[llhf/Meta-Llama-3.1-70B-Instruct, sllhf/Meta-...</td>\n",
              "      <td>[4.0, 3.0]</td>\n",
              "      <td>[The text provides accurate and informative co...</td>\n",
              "      <td>sllhf/Meta-Llama-3.1-405B-Instruct-FP8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Delete a part of the sentence that does not fi...</td>\n",
              "      <td>Science and Technology</td>\n",
              "      <td>[The part of the sentence that does not fit th...</td>\n",
              "      <td>{'raw_output_ultra_feedback_0': '#### Output f...</td>\n",
              "      <td>[llhf/Meta-Llama-3.1-70B-Instruct, sllhf/Meta-...</td>\n",
              "      <td>[5.0, 4.0]</td>\n",
              "      <td>[The output accurately identifies the part of ...</td>\n",
              "      <td>sllhf/Meta-Llama-3.1-405B-Instruct-FP8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Construct a daily schedule that allocates exac...</td>\n",
              "      <td>Health and Wellness</td>\n",
              "      <td>[Here is a daily schedule that allocates exact...</td>\n",
              "      <td>{'raw_output_ultra_feedback_0': '#### Output f...</td>\n",
              "      <td>[llhf/Meta-Llama-3.1-70B-Instruct, sllhf/Meta-...</td>\n",
              "      <td>[4.0, 3.0]</td>\n",
              "      <td>[The schedule provided is generally accurate a...</td>\n",
              "      <td>sllhf/Meta-Llama-3.1-405B-Instruct-FP8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If a particular argument hinges on an anecdota...</td>\n",
              "      <td>Others</td>\n",
              "      <td>[If an argument hinges on anecdotal evidence, ...</td>\n",
              "      <td>{'raw_output_ultra_feedback_0': '#### Output f...</td>\n",
              "      <td>[llhf/Meta-Llama-3.1-70B-Instruct, sllhf/Meta-...</td>\n",
              "      <td>[5.0, 1.0]</td>\n",
              "      <td>[The text provides accurate and informative co...</td>\n",
              "      <td>sllhf/Meta-Llama-3.1-405B-Instruct-FP8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29a1018d-155b-4dd2-b551-a0a946c95be8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29a1018d-155b-4dd2-b551-a0a946c95be8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29a1018d-155b-4dd2-b551-a0a946c95be8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-42b6c802-cd0c-4fb9-a970-a30e6d24bff8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42b6c802-cd0c-4fb9-a970-a30e6d24bff8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-42b6c802-cd0c-4fb9-a970-a30e6d24bff8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                         instruction                   topic  \\\n",
              "0  How can I create an efficient and robust workf...    Software Development   \n",
              "1  Is it possible to convert DC welding machine t...     Literature and Arts   \n",
              "2  Delete a part of the sentence that does not fi...  Science and Technology   \n",
              "3  Construct a daily schedule that allocates exac...     Health and Wellness   \n",
              "4  If a particular argument hinges on an anecdota...                  Others   \n",
              "\n",
              "                                         generations  \\\n",
              "0  [To create an efficient and robust workflow th...   \n",
              "1  [While it's technically possible to modify a D...   \n",
              "2  [The part of the sentence that does not fit th...   \n",
              "3  [Here is a daily schedule that allocates exact...   \n",
              "4  [If an argument hinges on anecdotal evidence, ...   \n",
              "\n",
              "                                 distilabel_metadata  \\\n",
              "0  {'raw_output_ultra_feedback_0': '#### Output f...   \n",
              "1  {'raw_output_ultra_feedback_0': '#### Output f...   \n",
              "2  {'raw_output_ultra_feedback_0': '#### Output f...   \n",
              "3  {'raw_output_ultra_feedback_0': '#### Output f...   \n",
              "4  {'raw_output_ultra_feedback_0': '#### Output f...   \n",
              "\n",
              "                                         model_names     ratings  \\\n",
              "0  [llhf/Meta-Llama-3.1-70B-Instruct, sllhf/Meta-...  [5.0, 1.0]   \n",
              "1  [llhf/Meta-Llama-3.1-70B-Instruct, sllhf/Meta-...  [4.0, 3.0]   \n",
              "2  [llhf/Meta-Llama-3.1-70B-Instruct, sllhf/Meta-...  [5.0, 4.0]   \n",
              "3  [llhf/Meta-Llama-3.1-70B-Instruct, sllhf/Meta-...  [4.0, 3.0]   \n",
              "4  [llhf/Meta-Llama-3.1-70B-Instruct, sllhf/Meta-...  [5.0, 1.0]   \n",
              "\n",
              "                                          rationales  \\\n",
              "0  [The output provides a clear, step-by-step gui...   \n",
              "1  [The text provides accurate and informative co...   \n",
              "2  [The output accurately identifies the part of ...   \n",
              "3  [The schedule provided is generally accurate a...   \n",
              "4  [The text provides accurate and informative co...   \n",
              "\n",
              "                               model_name  \n",
              "0  sllhf/Meta-Llama-3.1-405B-Instruct-FP8  \n",
              "1  sllhf/Meta-Llama-3.1-405B-Instruct-FP8  \n",
              "2  sllhf/Meta-Llama-3.1-405B-Instruct-FP8  \n",
              "3  sllhf/Meta-Llama-3.1-405B-Instruct-FP8  \n",
              "4  sllhf/Meta-Llama-3.1-405B-Instruct-FP8  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distiset['default']['train'].to_pandas().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFYe7ni0glzX"
      },
      "source": [
        "Optionally, we can push the dataset to the Hub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK6JBGvySrAr"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# set a secret in colab with enough rights to write repos\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "distiset.push_to_hub(\n",
        "    \"argilla/synthetic-data-generation-with-llama3-405B\",\n",
        "    token=hf_token,\n",
        "    private=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp79SC6ogryb"
      },
      "source": [
        "You can now explore the resulting dataset below. The most relevant columns are:\n",
        "\n",
        "- `generations`: A list of the two generated responses (70B and 405B), generated in the `generate` step.\n",
        "- `ratings`: A list with a rating for each response, generated by the `rate` step.\n",
        "- `rationales`: A list with rationale for the rating of each response, generated by the `rate` step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "cXr4JrwkSDZo",
        "outputId": "2450645b-3b97-417b-e7f0-ad9974b2a96e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<iframe src=\"https://huggingface.co/datasets/argilla/synthetic-data-generation-with-llama3-405B/embed/viewer/train\" width=\"80%\" height=\"560px\"></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "iframe_html = \"\"\"\n",
        "<iframe src=\"https://huggingface.co/datasets/argilla/synthetic-data-generation-with-llama3-405B/embed/viewer/train\" width=\"80%\" height=\"560px\"></iframe>\n",
        "\"\"\"\n",
        "display(HTML(iframe_html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwhh3kJpHv9z"
      },
      "source": [
        "ğŸ‰ Congrats! You've generated your first synthetic dataset with distilabel and Llama3.1 405B.\n",
        "\n",
        "The next section covers how to further configure the pipeline and introduces other useful out-of-the-box steps offered by distilabel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkZaQ281gvx1"
      },
      "source": [
        "## Advanced usage\n",
        "\n",
        "The above example, although simple, is effective and got us a nice dataset but we can try to improve it tweaking the generation parameters of the used LLMs or even combining a few LLMs to generate better texts. Let's see how!\n",
        "\n",
        "### Tweaking the generation parameters\n",
        "\n",
        "We can define new generation parameters for both the models we used to generate texts (`Llama 3.1 70B Instruct` and `Llama 3.1 405B Instruct`) and the model (`Llama 3.1 405B Instruct`) we used to rate those generations using the `parameters` argument of the `run` method:\n",
        "\n",
        "\n",
        "1. For the Llamas that will be used to generate text with the `TextGeneration` task we will define that we want them at max generating `512` tokens with the `max_new_tokens` parameter (default was `128`), and in addition we will set the `temperature` to `0.7` to make the probability distribution of the tokens predicted more uniform or random, so we get more rich and creative texts.\n",
        "2. For the Llama used to rate the generations with `UltraFeedback` task we will set the maximun number of tokens to be generated to `2048`, as the LLM will have to generate a rationale and score for each generation (in this case 2) so we want to be sure that the LLM will have enough tokens to do so. In this case, as we're using an LLM to annotate the generations, we want it to be as deterministic as possible so we will set the `temperature` to `0.1`.\n",
        "\n",
        "In most of the cases, setting the `max_new_tokens` and `temperature` is enough to achieve the results that we want, but we can define [much more parameters](https://distilabel.argilla.io/latest/api/llm/huggingface/#distilabel.llms.huggingface.inference_endpoints.InferenceEndpointsLLM.agenerate) such as the `top_p` and `top_k` to adjust even more the tokens generated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHchLCjQQdwE"
      },
      "outputs": [],
      "source": [
        "parameters={\n",
        "    # Llama 3.1 70B Instruct used for text generation\n",
        "    generate[0].name: {\n",
        "        \"llm\": {\n",
        "            \"generation_kwargs\": {\n",
        "                \"max_new_tokens\": 512,\n",
        "                \"temperature\": 0.7,\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    # Llama 3.1 405B Instruct used for text generation\n",
        "    generate[1].name: {\n",
        "        \"llm\": {\n",
        "            \"generation_kwargs\": {\n",
        "                \"max_new_tokens\": 512,\n",
        "                \"temperature\": 0.7,\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    # Llama 3.1 405B Instruct used judging responses\n",
        "    rate.name: {\n",
        "        \"llm\": {\n",
        "            \"generation_kwargs\": {\n",
        "                \"max_new_tokens\": 2048,\n",
        "                \"temperature\": 0.1\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq4W3QknKzZI"
      },
      "source": [
        "### Testing the new generation parameters with `dry_run`\n",
        "\n",
        "As we're trying new parameters (or if it's the first time executing the pipeline), it's not ideal to execute the pipeline with the whole dataset, as it could fail or the results are not as we expected, wasting money and time.\n",
        "\n",
        "To test that everything works as expected with a small subset of the dataset, we can use the `dry_run` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyOBQkAAQkiN"
      },
      "outputs": [],
      "source": [
        "distiset = pipeline.dry_run(parameters=parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD0UgwmFRe6F"
      },
      "source": [
        "Cool! It worked flawlessly! Now that we're sure, let's execute the pipeline again but this time with the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW4Mtq-HRFiv"
      },
      "outputs": [],
      "source": [
        "distiset = pipeline.run(parameters=parameters, use_cache=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT2G5hK3TFz9"
      },
      "source": [
        "### Combining a few LLMs to generate better responses\n",
        "\n",
        "We can even try to go a step further and use a Mixture-of-Agents (MoA) to combine a few LLMs to try generating richer and better responses.\n",
        "\n",
        "The idea behind MoA is quite simple:\n",
        "\n",
        "1. We have a few LLMs that we will call proposers generating an output for a given input. We will do this certain number of times, providing the previous outputs in the system prompt. This little trick will help the LLM to generate better responses every turn even if the previous outputs are not very good. In order to cover as much fields as possible, it's better to use specialized LLMs as proposers.\n",
        "2. We have a final LLM that we will call aggregator. This aggregator LLM will receive the outputs of the proposers to create and aggregated final output. For the aggregator LLM, we will want to use an LLM that it's proficient at generating text and aggregating the outputs to synthesize a high-quality response.\n",
        "\n",
        "So... what can be a good LLM to be used as an aggregator? ğŸ¤”\n",
        "\n",
        "Yes, you guessed it! ğŸ‰ `Llama 3.1 405B Instruct`\n",
        "\n",
        "For the proposers LLMs we will use the following models available with [Inference for PROs](https://huggingface.co/blog/inference-pro):\n",
        "\n",
        "- `Code Llama Instruct`: a conversational code assistant. Good at coding ğŸ‘¨ğŸ»â€ğŸ’»\n",
        "- `Llama 3.1 70B Instruct`: a good chat model that is good at everything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln3HXwjKWo3W"
      },
      "outputs": [],
      "source": [
        "from distilabel.llms import InferenceEndpointsLLM, MixtureOfAgentsLLM\n",
        "from distilabel.pipeline import Pipeline\n",
        "from distilabel.steps import LoadDataFromHub\n",
        "from distilabel.steps.tasks import TextGeneration, UltraFeedback\n",
        "from distilabel.steps import CombineColumns\n",
        "\n",
        "with Pipeline(name=\"synthetic-data-with-llama3-moa\") as pipeline:\n",
        "    load_dataset = LoadDataFromHub(\n",
        "        repo_id= \"argilla/10Kprompts-mini\"\n",
        "    )\n",
        "\n",
        "    generate = TextGeneration(\n",
        "        llm=MixtureOfAgentsLLM(\n",
        "            proposers_llms=[\n",
        "                InferenceEndpointsLLM(\n",
        "                    model_id=\"codellama/CodeLlama-34b-Instruct-hf\",\n",
        "                    generation_kwargs={\n",
        "                        \"max_new_tokens\": 1024,\n",
        "                        \"temperature\": 0.7,\n",
        "                    }\n",
        "                ),\n",
        "                InferenceEndpointsLLM(\n",
        "                    model_id=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
        "                    generation_kwargs={\n",
        "                        \"max_new_tokens\": 1024,\n",
        "                        \"temperature\": 0.7,\n",
        "                    }\n",
        "                ),\n",
        "            ],\n",
        "            aggregator_llm=InferenceEndpointsLLM(\n",
        "                model_id=\"meta-llama/Meta-Llama-3.1-405B-Instruct-FP8\",\n",
        "                generation_kwargs={\n",
        "                    \"max_new_tokens\": 1024,\n",
        "                    \"temperature\": 0.7,\n",
        "                }\n",
        "            )\n",
        "        ),\n",
        "        num_generations=2,\n",
        "        group_generations=True,\n",
        "    )\n",
        "\n",
        "    combine = CombineColumns(\n",
        "      columns=[\"generation\", \"model_name\"],\n",
        "      output_columns=[\"generations\", \"model_names\"]\n",
        "    )\n",
        "\n",
        "    rate = UltraFeedback(aspect=\"overall-rating\", llm=InferenceEndpointsLLM(\n",
        "        model_id=\"meta-llama/Meta-Llama-3.1-405B-Instruct-FP8\",\n",
        "        generation_kwargs={\n",
        "            \"max_new_tokens\": 2048,\n",
        "            \"temperature\": 0.0,\n",
        "        }\n",
        "    ))\n",
        "\n",
        "    load_dataset >> generate >> combine >> rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy8xXN0oa2d6"
      },
      "outputs": [],
      "source": [
        "distiset = pipeline.run(use_cache=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ4RdIPYgv5P"
      },
      "source": [
        "## What's next?\n",
        "\n",
        "This notebook has scratched the surface of what's possible with the new Llama 3.1 models and distilabel. There's many things to discover and experiment with.\n",
        "\n",
        "This notebook uses Hugging Face Inference Endpoints for PROs. This is good for experimentation. For larger datasets we recommend using local LLMs, TGI, vLLM, and even the upcoming Ray integration for running data generation on GPU clusters.\n",
        "\n",
        "Regarding the pipelines, the best place to discover out-of-the-box components is the [Component Gallery](https://distilabel.argilla.io/latest/components-gallery/).\n",
        "\n",
        "But probably the biggest strength of distilabel is the ability to develop your custom components on top a scalable and robust data generation framework, you can read this [guide to get started](https://distilabel.argilla.io/latest/sections/how_to_guides/basic/step/#define-steps-for-your-pipeline)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "009b1d2a829d4e31b651f67ccb1f1d9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04f647b1b21e4a10896440a21e81a7ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b7d513bd8884f919c565aaf5e69e986": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d0f4e3b92f14918a5ac82dc898c3083": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17eb2bcf26404cd5b326dda6553bfd03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2068afbcad714221a55a9255e9059ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20dc723717b348eb85b7e48d39cecbab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601141c9ebff44ffaf64d6b8b77575ce",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b8f6c5d693d744289b6275913523d08f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "235485e2ceae48b5ad74041b137ec894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_0d0f4e3b92f14918a5ac82dc898c3083",
            "style": "IPY_MODEL_715d2b367ceb4e84ae7f8859454f17b6",
            "value": true
          }
        },
        "2455b9373b324c2b837097f241419034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc8819a425c24f97a5e54ec8e2e1a8e2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_af498a88d197460eb2755358c5986d3e",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "31c731c8754747169c4c12810f7581f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2068afbcad714221a55a9255e9059ee7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c5de62cf1901423ea8c18100210ea3c7",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "37b0eade00b94af8bc7b890ea6135d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b33356e1bdb14ae88e446d2a4395a023",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_be4fb65648a949bda9831cf0dee42482",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "601141c9ebff44ffaf64d6b8b77575ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ad19c9a2ec44f66ad5b0a6a337123a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eeb7762809c479a84927ea52e729825": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f9f650f11104badaded5e493c11bec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "715d2b367ceb4e84ae7f8859454f17b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76bb535338424f36b2e183d45264c5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6eeb7762809c479a84927ea52e729825",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0b7d513bd8884f919c565aaf5e69e986",
            "value": ""
          }
        },
        "7a177492a4b1496985892ffc377a23d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17eb2bcf26404cd5b326dda6553bfd03",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ab96b9564f6347af93acd10d846750bb",
            "value": "Login successful"
          }
        },
        "7f56bae1e921469cb12ce02f8a0d36b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "89f4e4bc90a74280b2533f5e36563464": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3b428795ce849208b4583bfd88f54fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_009b1d2a829d4e31b651f67ccb1f1d9f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ae98e8056275444883649e62299ee6ab",
            "value": "Token is valid (permission: write)."
          }
        },
        "ab96b9564f6347af93acd10d846750bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae935b27bf8742a09985259a67377ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ad19c9a2ec44f66ad5b0a6a337123a7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_89f4e4bc90a74280b2533f5e36563464",
            "value": "Connecting..."
          }
        },
        "ae98e8056275444883649e62299ee6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aecd2c76f1de4cacad538e8eafa0866d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_04f647b1b21e4a10896440a21e81a7ac",
            "style": "IPY_MODEL_6f9f650f11104badaded5e493c11bec6",
            "tooltip": ""
          }
        },
        "af498a88d197460eb2755358c5986d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b33356e1bdb14ae88e446d2a4395a023": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8f6c5d693d744289b6275913523d08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc8819a425c24f97a5e54ec8e2e1a8e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be4fb65648a949bda9831cf0dee42482": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5de62cf1901423ea8c18100210ea3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fceafd6471364cf7a3084f8b4df69fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3b428795ce849208b4583bfd88f54fa",
              "IPY_MODEL_2455b9373b324c2b837097f241419034",
              "IPY_MODEL_37b0eade00b94af8bc7b890ea6135d12",
              "IPY_MODEL_7a177492a4b1496985892ffc377a23d9"
            ],
            "layout": "IPY_MODEL_7f56bae1e921469cb12ce02f8a0d36b8"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
